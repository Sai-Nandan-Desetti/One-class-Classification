{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7n1F5d6r0lWJmVf89axxo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ngEjhuaYULJg"},"outputs":[],"source":["%cd /content/drive/MyDrive/M.Tech CS_2022-23/Project/One Class Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F7FFt23REZ0K"},"outputs":[],"source":["import os\n","import pickle\n","import numpy as np\n","import torch\n","from tqdm import tqdm\n","from collections import defaultdict\n","import torch.autograd as autograd\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","import scipy.stats\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_fscore_support\n","import pandas as pd"]},{"cell_type":"code","source":["data_path = './data/CIFAR10/'\n","\n","train_dataset = torchvision.datasets.CIFAR10(data_path, train=True, download=True)\n","test_dataset  = torchvision.datasets.CIFAR10(data_path, train=False, download=True)"],"metadata":{"id":"CSbWG1oiEggx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_transform = transforms.ToTensor()\n","test_transform = transforms.ToTensor()"],"metadata":{"id":"zuvef3AEEkIQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_class_c(x, y, c):    \n","  y = np.array(y)\n","  pos_c = np.argwhere(y == c)\n","  pos_c = list(pos_c[:, 0])\n","  class_c_data = [x[i] for i in pos_c]\n","  return class_c_data, [c]*len(pos_c)"],"metadata":{"id":"qXltw3TVEr6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DatasetMaker(Dataset):\n","  def __init__(self, true_label, data, targets, transform_func=None):\n","    super().__init__()    \n","    self.data = data\n","    self.targets = targets\n","    self.true_label = true_label\n","    self.transform_func = transform_func\n","\n","  def __getitem__(self, idx):\n","    img, target = self.data[idx], self.targets[idx]\n","    if self.transform_func:\n","      img = self.transform_func(img)\n","    return img, target == self.true_label\n","\n","  def __len__(self):\n","    return len(self.targets)\n","\n","\n","def prepare_oc_dataset(dataset, class_label):\n","  # get single class (class_label) data\n","  data, targets = get_class_c(dataset.data, dataset.targets, class_label)\n","  return data, targets"],"metadata":{"id":"UbgZxZEFEvWE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 256"],"metadata":{"id":"418T-whiZn61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","cuda = True if device == 'cuda' else False\n","if cuda: torch.cuda.set_device(0)"],"metadata":{"id":"tXotxVIME22s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MLP(nn.Module):\n","  def __init__(self, num_outputs, num_hiddens):\n","    super(MLP, self).__init__()\n","    self.net = nn.Sequential(nn.Flatten(),\n","                             *[nn.Sequential(nn.LazyLinear(nh, bias=False), nn.LeakyReLU()) for nh in num_hiddens]                             \n","                             ) \n","    self.fc = nn.LazyLinear(num_outputs, bias=False)   \n","  \n","  def forward(self, X):\n","    X = self.net(X)\n","    return X, self.fc(X)"],"metadata":{"id":"OgnKTKEEE6wy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["c = .5\n","l = 6.5\n","s = 0.5"],"metadata":{"id":"R9B4BdjrtqVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_epoch(model, dataloader, optimizer):\n","  model.train()  \n","  train_loss = []\n","  \n","  for inputs, _ in dataloader:\n","    inputs = inputs.to(device)\n","    inputs.requires_grad = True\n","    features, op = model(inputs)\n","\n","    with torch.no_grad():\n","      triangular_samples = torch.from_numpy(scipy.stats.triang.rvs(c, l, s, features.shape[0])).to(device)      \n","          \n","    triangle = ((torch.linalg.norm(features, dim=1) - triangular_samples) ** 2).mean()    \n","    loss = triangle\n","    \n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    train_loss.append(loss.detach().cpu())\n","\n","  return train_loss"],"metadata":{"id":"z94KLQKaFLsp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(model, dataloader):\n","  model.train(False)\n","  model.eval()\n","  outputs, labels, norms = [], [], []\n","  for input_batch, label_batch in dataloader:\n","    input_batch = input_batch.to(device)           \n","    norm = torch.linalg.norm(model(input_batch)[0], dim=1).detach().cpu()    \n","    outputs.append(torch.logical_and(norm >= l, norm <= l+s))        \n","    labels.append(label_batch)\n","    norms.append(norm)\n","  return torch.cat(outputs), torch.cat(labels), torch.cat(norms)\n","\n","\n","def compute_scores(labels, outputs):  \n","  return precision_recall_fscore_support(labels, outputs)[:-1]"],"metadata":{"id":"UudAtI47Ly1n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 15\n","\n","# acc_scores = defaultdict(list)\n","precision = defaultdict(list)\n","recall = defaultdict(list)\n","f1_scores = defaultdict(list)\n","  \n","# For each class\n","for true_label in range(10):\n","  \n","  # prepare the data and\n","  train_data, train_targets = prepare_oc_dataset(train_dataset, true_label)\n","  train_oc_dataset = DatasetMaker(true_label, train_data, train_targets, train_transform)\n","  test_oc_dataset = DatasetMaker(true_label, test_dataset.data, test_dataset.targets, test_transform)\n","  train_loader = DataLoader(train_oc_dataset, batch_size=batch_size, shuffle=True)\n","  test_loader = DataLoader(test_oc_dataset, batch_size=batch_size, shuffle=False)\n","  \n","  # run the experiment five times...\n","  for experiment in range(5):    \n","\n","    # instantiate the model\n","    model = MLP(num_outputs=1, num_hiddens=[900, 300]).to(device)\n","    # optimizer\n","    optimizer = torch.optim.Adam(model.parameters())\n","\n","    # train the model    \n","    for epoch in range(num_epochs):\n","      batchwise_losses = train_epoch(model, train_loader, optimizer)\n","      train_epoch_loss = np.mean(batchwise_losses)      \n","\n","    # test time\n","    model_outputs, labels, norms = test(model, test_loader)\n","\n","    # compute the results\n","    prec, rec, f1 = compute_scores(labels, model_outputs)\n","\n","    # store the results\n","    precision[true_label].append(prec)\n","    recall[true_label].append(rec)\n","    f1_scores[true_label].append(f1)    "],"metadata":{"id":"F1tEHGvXZNL6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for label, scores in precision.items():\n","  print(f'Class: {label}\\tMean Accuracy: {np.mean(scores):.4f}')"],"metadata":{"id":"vlm2iMMBpuLq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for label, scores in recall.items():\n","  print(f'Class: {label}\\tMean Accuracy: {np.mean(scores):.4f}')"],"metadata":{"id":"GNTkyBT7pr0o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for label, scores in f1_scores.items():\n","  print(f'Class: {label}\\tMean Accuracy: {np.mean(scores):.4f}')"],"metadata":{"id":"TXQsToJNZSOx"},"execution_count":null,"outputs":[]}]}